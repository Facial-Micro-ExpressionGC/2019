<!DOCTYPE html>
<!--[if lt IE 7]> <html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> 
<![endif]-->
<!--[if IE 7]> <html class="no-js lt-ie9 lt-ie8" lang="en"> 
<![endif]-->
<!--[if IE 8]> <html class="no-js lt-ie9" lang="en"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
	<head>
<!-- 
Timeline Template
http://www.templatemo.com/preview/templatemo_427_timeline
-->
		<title>MEGC2019</title>
        <meta name="description" content="">
        <meta name="author" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta charset="UTF-8">

        <link rel="stylesheet" type="text/css" href="css/bootstrap.min.css">
        <link rel="stylesheet" type="text/css" href="css/font-awesome.min.css">
        <link rel="stylesheet" type="text/css" href="css/templatemo-style.css">

        <!-- JavaScripts -->
        <script src="js/vendor/jquery-1.10.2.min.js"></script>
        <script src="js/vendor/modernizr.min.js"></script>
        <script src="http://maps.googleapis.com/maps/api/js?key=AIzaSyDY0kkJiTPVd2U7aTOAwhc9ySH6oHxOIYM">
        </script>

	</head>
	<body>
    
    <header class="site-header" id="top">
        <nav class="navbar navbar-default navbar-fixed-top">
            <div class="container">
                <div class="row">
                    <div class="navbar-header">
                        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse">
                          <i class="fa fa-bars"></i>
                        </button>
                        <div class="logo-wrapper">
                            <a class="navbar-brand" href="#templatemo">
                                <p>MEGC2019</em></p>
                            </a>
                        </div>  
                    </div>
                    <div class="collapse navbar-collapse" id="main-menu">
                        <ul class="nav navbar-nav navbar-right">
                            <li><span></span><a href="#top" class="home">Home</a></li>
                            <li><span></span><a href="#first-section" class="about">Submissions</a></li>
                            <li><span></span><a href="#second-section" class="portfolio">Organizers</a></li>
                            <li><span></span><a href="#map" class="map">Location</a></li>
                            <li><span></span><a href="#third-section" class="contact">Contact</a></li>
                        </ul>
                    </div>
                </div> 
            </div>
        </nav>
    </header>

    <div id="big-banner">
        <div class="container">
            <div class="row">
                <div class="col-md-12 col-xs-12">
                   <ul class="main-icons">
                        <li><a href="#"><i class="fa fa-bolt"></i>Grand Challenge</a></li>
                        <!--<li><a href="#"><i class="fa fa-video-camera"></i></a></li>-->
                        <!--<li><a href="#"><i class="fa fa-music"></i>Our Music</a></li>-->
                        <li><a href="#"><i class="fa fa-bolt"></i>More challenge</a></li>
                    </ul>
                </div>
            </div>
        </div>               
    </div>

    
    <div id="first-section">
        <div class="heading">
            <div class="container">
                <div class="row">
                    <div class="col-md-12">
                            <h2 class="header-section-title">Submissions</h2>
                    </div> 
                </div>
            </div>
        </div>
    </div>

    <div id="first-section1">
        <div class="container">
            <div class="row">
                <div class="triangle"></div>
            </div>
            <div class="row">
                <div class="col-md-12">
                    <section id="cd-timeline" class="cd-container">
                        <div class="cd-timeline-block">
                            <div class="cd-timeline-img cd-picture">
                                <img src="images/first-icon.png" alt="Picture">
                            </div>
                            <div class="cd-timeline-content service-box-content">
                                <h3>Advisory Panel:</h3>
					<p>Xiaolan Fu, Chinese Academy of Sciences, China</p>
					<br />
					<br />
					<p>Guoying Zhao, University of Oulu, Finland<p><br />
                            </div>
                        </div>

                        <div class="cd-timeline-block">
                            <div class="cd-timeline-img cd-movie">
                                <img src="images/second-icon.png" alt="Picture">
                            </div>
                            <div class="cd-timeline-content service-box-content">
                                <h3>Tentative paper submission and review schedule</h3>
					<p>Submission deadline: 27 January 2019</p><br />
					<br />
					<p>Notification: 12 February 2019<br />
					<br />
					<p>Camera-ready: 15 February 2019</p>
                            </div>
                        </div>

			    
                        <div class="cd-timeline-block">
                            <div class="cd-timeline-img cd-icon">
                                <img src="images/third-icon.png" alt="Picture">
                            </div>
				 <div class="cd-timeline-content service-box-content">
					 <h3>Planned advertisement means, website hosting</h3>
					<p><a href="https://cmt3.research.microsoft.com/User/Login?ReturnUrl=%2FMEGC2018" class="templatemo-item">Submit paper here</a></p>
					<p>Workshop will be advertised at various websites, and by email circulation and social media.</p>       
                            </div>
                        </div> 

			    
                        <div class="cd-timeline-block">
                            <div class="cd-timeline-img cd-location">
                                <img src="images/fourth-icon.png" alt="Picture">
                            </div>
                            <div class="cd-timeline-content service-box-content">
                               <h3>Paper review procedure (single/double-blind, internal/external, solicited/invited-only,pool of reviewers, etc.)</h3>
					<p>Double-blind, each paper to be reviewed by a minimum of 2 reviewers</p>
                            </div>
                        </div>
			    
			                            <div class="cd-timeline-block">
                            <div class="cd-timeline-img cd-location">
                                <img src="images/fourth-icon.png" alt="Picture">
                            </div>
                            <div class="cd-timeline-content service-box-content">
                                <h3>Estimated number of submissions and acceptance rate</h3>
					<p>30 submissions with acceptance rate 40%.</p>
                            </div>
                        </div>
			    
			                            <div class="cd-timeline-block">
                            <div class="cd-timeline-img cd-location">
                                <img src="images/fourth-icon.png" alt="Picture">
                            </div>
                            <div class="cd-timeline-content service-box-content">
                                <h3>Special space or equipment requests, if any</h3>
					<p>N/A</p>
                            </div>
                        </div>
			    
			                            <div class="cd-timeline-block">
                            <div class="cd-timeline-img cd-location">
                                <img src="images/fourth-icon.png" alt="Picture">
                            </div>
                            <div class="cd-timeline-content service-box-content">
                                <h3>Specify if there will be non-peer reviewed invited paper, if so, how many?</h3>
					<p>N/A</p>
                            </div>
                        </div>
			    
			                            <div class="cd-timeline-block">
                            <div class="cd-timeline-img cd-location">
                                <img src="images/fourth-icon.png" alt="Picture">
                            </div>
                            <div class="cd-timeline-content service-box-content">
                                <h1>Organizers</h1></br>
			<h1>List of organizers including affiliation, email address, and short bio</h1>
                            </div>
                        </div>
			    
			                            <div class="cd-timeline-block">
                            <div class="cd-timeline-img cd-location">
                                <img src="images/fourth-icon.png" alt="Picture">
                            </div>
                            <div class="cd-timeline-content service-box-content">
                                <h3>Paper submission procedure (submission via web site, via email, etc.) if applicable </h3>
					<p><a href ="https://fg2018.cse.sc.edu/submissions.html.">submit instructions here</a></p>
					<p>Easy chair / CMT (tbc) </p>
                            </div>
                        </div>
			    
                    </section>
                </div>
            </div>
        </div>
    </div>

    <div id="cta">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h4>About Us</h4>
                    <h1>The Second Facial Micro-Expression Grand Challenge (MEGC): Spotting and Recognition</h1>
		    <br><br>
		   <h2>Workshop motivation, expected outcomes and impact</h2><br />
<p>Facial micro-expressions (MEs) are involuntary movements of the face that occur spontaneously when a person 
experiences an emotion but attempts to suppress or repress the facial expression, typically found in a high-stakes 
environment.As such, the duration of MEs is very short with the general duration of not more than 500 milliseconds (ms), and is the telltale sign that distinguishes them from a normal facial expression. 
Computational analysis and automation of tasks on micro-expressions is an emerging area in face research,with a strong interest appearing as recent as 2014.
Only recently, the availability of a few spontaneously induced facial micro-expression datasets has provided the impetus to advance further from the computational aspect.
Particularly comprehensive are two state-of-the-art FACS coded datasets: the Chinese Academy of Sciences Micro-Expression 
Database II (CASME II) with 247 MFEs at 200 fps and the Spontaneous Facial Micro-Movement Dataset (SAMM) with 159 MFEs at 200 fps.
In addition, there is recent interest in acquiring “in-the-wild” datasets to further introduce real-world scenarios. 
While much research has been done on these datasets individually, there have been little attempts to introduce a more rigorous and realistic evaluation to work done in this domain.
This is the second edition of this workshop, which aims to promote interactions between researchers and scholars not only from within this 
niche area of facial micro-expression research, but also including those from broader, general areas of expression 
and psychology research.</p>
			<br><br>
		    </div>   
            </div>
        </div>
    </div>

    <div id="second-section">
        <div class="heading">
            <div class="container">
                <div class="row">
                    <div class="col-md-12">
                            <h2>ORGANIZERS</h2>
                    </div> 
                </div>
            </div>
        </div>
    </div>
    
    <div id="second-section2">
        <div class="container">
            <div class="row">
                <div class="triangle"></div>
            </div>
            <div class="row">
                <div class="col-md-12">
                    <section id="cd-timeline-2" class="cd-container">
                        <div class="cd-timeline-block">
                            <div class="cd-timeline-img cd-picture">
                                <img src="images/camera-icon.png" alt="Picture">
                            </div>

                            <div class="cd-timeline-content projects">
                                <img src="images/project-1.jpg" alt="">
                                <div class="project-content">
                                    <h3>Moi Hoon Yap</h3>		
	<p>Manchester Metropolitan University,UK, m.yap@mmu.ac.uk<br />
	Moi Hoon Yap received her PhD in Computer Science from Loughborough University in 2009.<br />
	She is a Reader (Associate Professor) in Computer Vision at the Manchester Metropolitan University and a Royal Society Industry Fellow with Image Metrics Ltd.<br />
	She leads the Human-Centred Computing Group and the lead contributor of SAMM dataset.<br />
	Her research is funded by The Royal Society, EU funding, Innovate UK and industrial funding.<br />
	Her research expertise is in computer vision, deep learning, image/video processing on face and gesture analysis.</p>
                                    <!--<span>18 December 2084</span>-->
                                </div>
                            </div>
                        </div>

                        <div class="cd-timeline-block">
                            <div class="cd-timeline-img cd-picture">
                                <img src="images/camera-icon.png" alt="Picture">
                            </div>

                            <div class="cd-timeline-content projects">
                                <img src="images/project-2.jpg" alt="">
                                <div class="project-content">
                                    					<h3>Sujing Wang</h3>
	 <p>Chinese Academy of Sciences, China, wangsujing@psych.ac.cn.<br />
	 Sujing Wang received his Master's degree from the Software College of Jilin University, Changchun, China, in 2007.<br />
	 He received the Ph.D. degree from the College of Computer Science and Technology of Jilin University in 2012.<br />
         He was a postdoctoral researcher in Institute of Psychology, Chinese Academy of Sciences from 2012 to 2015.<br />
	 He is now an Associate Researcher in Institute of Psychology, Chinese Academy of Sciences.<br />
         He has published more than 50 scientific papers.<br />
         He is One of Ten Selectees of the Doctoral Consortium at International Joint Conference on Biometrics 2011.<br />
	 He was called as Chinese Hawkin by the Xinhua News Agency. His current research interests include pattern recognition,<br /> 
	 computer vision and machine learning. He serves as an associate editor of Neurocomputing (Elsevier).</p>
                                   <!-- <span>12 December 2084</span>-->
                                </div>
                            </div>
                        </div>

                        <div class="cd-timeline-block">
                            <div class="cd-timeline-img cd-picture">
                                <img src="images/camera-icon.png" alt="Picture">
                            </div>

                            <div class="cd-timeline-content projects">
                                <img src="images/project-3.jpg" alt="">
                                <div class="project-content">
                                    					<h3>John See</h3>
	<p>Multimedia University, Malaysia, johnsee@mmu.edu.my<br/>
	John See received his PhD in Computer Science, MEngSc and BEng degrees from Multimedia University (MMU), Malaysia.<br />
	He is currently a Senior Lecturer at Multimedia University where he leads the Visual Processing Laboratory under the Centre for Visual Computing.<br />
	He is also currently a Visiting Research Fellow to Shanghai Jiao Tong University, China.<br />
	Dr. See has published more than 50 articles in reputable journals and conferences such as IEEE T-AC, IEEE T-CE, ICCV, ICIP, ACCV, and FG,<br />
	and has also served as chair of several workshops and special sessions in various international computer vision and signal processing conferences worldwide.<br />
	He will be serving as Program Chair in IEEE MMSP 2019. His research interests cover a diverse range of topics in computer vision and pattern recognition, <br />
	particularly in the emerging fields of facial biometrics, affective computing, computational aesthetics and deep learning.</p>
                                    <!--<span>10 December 2084</span>-->
                                </div>
                            </div>
                        </div>

                        <div class="cd-timeline-block">
                            <div class="cd-timeline-img cd-picture">
                                <img src="images/camera-icon.png" alt="Picture">
                            </div>

                            <div class="cd-timeline-content projects">
                                <img src="images/project-4.jpg" alt="">
                                <div class="project-content">
                                    					<h3>Xiaopeng Hong,</h3>
					<p>University of Oulu, Finland, hongxiaopeng.cn@gmail.com</p>
					<p>Xiaopeng Hong received his BEng and Ph.D. degrees in computer application and technology from Harbin Institute of Technology, Harbin, P. R. China, in 2004 and 2010 respectively. He is currently a Docent with the Center for Machine Vision and Signal Analysis, University of Oulu, Finland, where he has been a scientist researcher since 2011. Dr. Hong has published over 30 articles in mainstream journals and conferences such as IEEE T-PAMI, IEEE T-IP, IEEE CVPR and ACM UbiComp, and have one issued Chinese Patent. He has organized two international workshops and served as a reviewer for about 30 journals and conferences. His current research interests include the deep learning technology and other machine learning methods, especially their applications in multi-modal learning, affective computing, intelligent medical examination, and human-computer interaction, etc. His research has been reported by global media including MIT Technology Review and Daily Mail.</p
                                    <!--<span>30 November 2084</span>-->
                                </div>
                            </div>
                        </div>

                        <div class="cd-timeline-block">
                            <div class="cd-timeline-img cd-picture">
                                <img src="images/camera-icon.png" alt="Picture">
                            </div>

                            <div class="cd-timeline-content projects">
                                <img src="images/project-5.jpg" alt="">
                                <div class="project-content">
                                    <h2>Connah Kendrick</h2>
                                    <!--<span>22 November 2084</span>-->
                                </div>
                            </div>
                        </div>
                    </section>
                </div>
            </div>
        </div>
    </div>


    <div id="map">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h4>Visit Us</h4>
                    <p>This is where we operate</p>
                </div>   
            </div>
            <div class="row">
                <div class="map-content">
                    <div id="templatemo-map"></div>
                </div>
            </div>
        </div>
    </div>

    <div id="third-section">
        <div class="heading">
            <div class="container">
                <div class="row">
                    <div class="col-md-12">
                            <h2>Send Us A Message</h2>
                    </div> 
                </div>
            </div>
        </div>
    </div>
    
    <div id="third-section3">
        <div class="container">
            <div class="row">
                <div class="triangle"></div>
            </div>
            <div class="row">
                <div class="col-md-8">
                    <form class="form">
                        <div class="row">
                        <div class="name col-md-4">
                            <input type="text" name="name" id="name" placeholder="Name" />
                        </div>
                        <div class="email col-md-4">
                            <input type="text" name="email" id="email" placeholder="Email" />
                        </div>
                        <div class="subject col-md-4">
                            <input type="text" name="subject" id="subject" placeholder="Subject" />
                        </div> 
                        </div>
                        <div class="row">        
                            <div class="text col-md-12">
                                <textarea name="text" placeholder="Message"></textarea>
                            </div>   
                        </div>                              
                        <div class="submit">
                            <input type="submit" value="Send Now" />
                        </div>
                    </form>
                </div>
                <div class="col-md-4">
                    <div class="contact-discription">
                        <h4>More About Us!</h4>
                        <h3> This workshop has two main agenda:</h3>
			    <ol> 
				    <li>To organize the Second Grand Challenge for facial micro-expression research,
					involving cross-database recognition and spotting of micro-expressions.</li><p><a href="http://www2.docm.mmu.ac.uk/STAFF/m.yap/files/MEGC_Guidelines.pdf" class = " ">Download guidance here</a></p>
				    <li>To solicit original works that address a variety of challenges of ME research,but not limited to</li>
			    </ol>
					<br/>
			    <ul>
				    <li>ME spotting/detection</li>
				    <li>ME recognition</li>
				    <li>ME feature representation and computational analysis</li>
				    <li>Unified ME spot-and-recognize schemes</li>
				    <li>Deep learning techniques for MEs spotting and recognition</li>
				    <li>MEs data analysis and synthesis</li>
				    <li>New datasets for MEs</li>
				    <li>Psychology of MEs</li>
			    </ul> 
                        <br><br>
                        <strong>Mailing Address:</strong><br>
                        <p>Manchester Metropolitan University
			    John Dalton Building(E129). Chester Street Manchester M1 5GD</p>
                        <br><br>
                        Tel: (+44)01612471503<br>
						Email: M.Yap@mmu.ac.uk
                        <br><br>
                        
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </div>

    
    <footer>
        <div class="container">
            <div class="footer-content">
                <div class="row">
                    <div class="col-md-12">
                        <div class="col-md-4">
                            <div class="copyright-text">
                                <p>Copyright &copy; 2019 <a href="#">MEGC2019</a></p>
                            </div>
                        </div>
                        <div class="col-md-4">
                            <div class="back-to-top">
                                <a href="#top">Back To Top</a>
                            </div>
                        </div>
                        <div class="col-md-4">
                            <div class="social-icons">
                                <ul>
                                    <li><a href="#" class="#"><i class="fa fa-facebook"></i></a></li>
                                    <li><a href="#" class="#"><i class="fa fa-twitter"></i></a></li>
                                    <li><a href="#" class="#"><i class="fa fa-linkedin"></i></a></li>
                                    <li><a href="#" class="#"><i class="fa fa-rss"></i></a></li>
                                </ul>
                            </div>
                        </div>
                    </div>    
                </div>
            </div>
        </div>
    </footer>

    
		<!-- Javascripts -->
        <script>
        function initialize()
        {
        var mapProp = {
          center: new google.maps.LatLng(40.7828839,-73.9652425),
          zoom: 15,
		  scrollwheel: false,
          mapTypeId:google.maps.MapTypeId.ROADMAP
          };
        var map=new google.maps.Map(document.getElementById("templatemo-map")
          ,mapProp);
        }

        google.maps.event.addDomListener(window, 'load', initialize);
		google.maps.event.addDomListener(window, 'resize', function() 
		{
			map.setCenter(center);
		});
        </script>
		<script type="text/javascript" src="js/vendor/bootstrap.min.js"></script>
		<script type="text/javascript" src="js/custom.js"></script>

	</body>
</html>
